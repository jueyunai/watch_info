# 大模型 API 配置示例
# 复制此文件为 .env 并填入你的密钥

# 多厂商优先级配置(推荐)
# 按优先级顺序配置多个厂商,用逗号分隔,当某个厂商失败时自动尝试下一个
# 当前支持的模型提供商: openai | anthropic | qwen | deepseek | zhipu | minimax | kimi | ms-deepseek | ms-qwen
VITE_LLM_PROVIDERS=ms-deepseek,kimi,minimax,deepseek,ms-qwen,zhipu

# 单厂商配置(兼容旧版)
# 当前支持的模型提供商: openai | anthropic | qwen | deepseek | zhipu | minimax | kimi | ms-deepseek | ms-qwen
# 如果设置了 VITE_LLM_PROVIDERS,此配置将被忽略
VITE_LLM_PROVIDER=openai

# OpenAI
VITE_OPENAI_API_KEY=sk-xxx
VITE_OPENAI_BASE_URL=https://api.openai.com/v1
VITE_OPENAI_MODEL=gpt-4o

# Anthropic (Claude)
VITE_ANTHROPIC_API_KEY=sk-ant-xxx
VITE_ANTHROPIC_BASE_URL=https://api.anthropic.com
VITE_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# 通义千问 (Qwen)
VITE_QWEN_API_KEY=sk-xxx
VITE_QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
VITE_QWEN_MODEL=qwen-plus

# DeepSeek
VITE_DEEPSEEK_API_KEY=sk-xxx
VITE_DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
VITE_DEEPSEEK_MODEL=deepseek-chat

# 智谱 (GLM)
VITE_ZHIPU_API_KEY=xxx.xxx
VITE_ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4
VITE_ZHIPU_MODEL=glm-4-flash

# MiniMax
VITE_MINIMAX_API_KEY=xxx
VITE_MINIMAX_BASE_URL=https://api.minimax.chat/v1
VITE_MINIMAX_MODEL=MiniMax-M2.1

# Kimi (Moonshot)
VITE_KIMI_API_KEY=sk-xxx
VITE_KIMI_BASE_URL=https://api.moonshot.cn/v1
VITE_KIMI_MODEL=moonshot-v1-8k

# ModelScope - DeepSeek R1
VITE_MS_DEEPSEEK_API_KEY=ms-xxx
VITE_MS_DEEPSEEK_BASE_URL=https://api-inference.modelscope.cn/v1
VITE_MS_DEEPSEEK_MODEL=deepseek-ai/DeepSeek-R1-0528

# ModelScope - Qwen
VITE_MS_QWEN_API_KEY=ms-xxx
VITE_MS_QWEN_BASE_URL=https://api-inference.modelscope.cn/v1
VITE_MS_QWEN_MODEL=Qwen/Qwen3-235B-A22B-Instruct-2507
