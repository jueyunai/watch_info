# 大模型 API 配置示例
# 复制此文件为 .env 并填入你的密钥

# 多厂商优先级配置(推荐)
# 按优先级顺序配置多个厂商,用逗号分隔,当某个厂商失败时自动尝试下一个
# 当前支持的模型提供商: openai | anthropic | qwen | deepseek | zhipu | minimax
VITE_LLM_PROVIDERS=zhipu,deepseek,qwen

# 单厂商配置(兼容旧版)
# 当前支持的模型提供商: openai | anthropic | qwen | deepseek | zhipu | minimax
# 如果设置了 VITE_LLM_PROVIDERS,此配置将被忽略
VITE_LLM_PROVIDER=openai

# OpenAI
VITE_OPENAI_API_KEY=sk-xxx
VITE_OPENAI_BASE_URL=https://api.openai.com/v1
VITE_OPENAI_MODEL=gpt-4o

# Anthropic (Claude)
VITE_ANTHROPIC_API_KEY=sk-ant-xxx
VITE_ANTHROPIC_BASE_URL=https://api.anthropic.com
VITE_ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# 通义千问 (Qwen)
VITE_QWEN_API_KEY=sk-xxx
VITE_QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
VITE_QWEN_MODEL=qwen-plus

# DeepSeek
VITE_DEEPSEEK_API_KEY=sk-xxx
VITE_DEEPSEEK_BASE_URL=https://api.deepseek.com/v1
VITE_DEEPSEEK_MODEL=deepseek-chat

# 智谱 (GLM)
VITE_ZHIPU_API_KEY=xxx.xxx
VITE_ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4
VITE_ZHIPU_MODEL=glm-4-flash

# MiniMax
VITE_MINIMAX_API_KEY=xxx
VITE_MINIMAX_BASE_URL=https://api.minimax.chat/v1
VITE_MINIMAX_MODEL=abab6.5s-chat
